# DACN: Dual-Attention Convolutional Network for Hyperspectral Image Super-Resolution

Convolutional neural networks (CNNs) have gained significant interest for hyperspectral super-resolution tasks; however, one of their weaknesses is that they operate only on local neighborhoods, thereby missing global information. Although attention has gained significant interest as an advancement, it has mostly been applied to sequence modeling and generative modeling tasks. Inspired by the concept of self-attention, we introduce DACN, a dual-attention convolutional network for hyperspectral image super-resolution. Specifically, the model first employ multi-head attention to enhance the representational power. Next, we infer separate attention maps for the channel and spatial dimensions. These maps are then multiplied with the input feature map to achieve adaptive feature refinement. Finally, we integrate a composite loss function that combines traditional L2 regularization with a spatial-spectral gradient loss, ensuring that both structural details and spectral integrity are preserved during training. Experimental results on two hyperspectral datasets demonstrate the efficiency of our model, and we conclude that the best results are obtained when combining both self-attention and attention. 
