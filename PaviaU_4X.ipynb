{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1eb1e9-d97c-42a4-aafc-3d497c297a7d",
   "metadata": {},
   "source": [
    "## DACN: Dual-Attention Convolutional Network for Hyperspectral Image Super-Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7de5cc-1725-4283-9eb4-1ed452805447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io import loadmat \n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.layers import Conv2DTranspose, BatchNormalization, LeakyReLU, Add, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Dense, GlobalAveragePooling2D, Reshape, Multiply, Activation, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697d14b-ab2f-4ff8-b9fd-29849a47f81b",
   "metadata": {},
   "source": [
    "## Preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd4f01-7ea4-45e7-b091-22e02ce83fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set all seeds for reproducibility\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# Ensure TensorFlow uses deterministic operations\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Load the Pavia dataset\n",
    "try:\n",
    "    data = loadmat(\"PaviaU.mat\")  # Ensure that the file path is correct\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading .mat file: {e}\")\n",
    "\n",
    "# Access the hyperspectral image using the correct key 'paviaU'\n",
    "print(\"Keys in loaded .mat file:\", data.keys())\n",
    "if 'paviaU' in data:\n",
    "    hyperspectral_image = data['paviaU']\n",
    "else:\n",
    "    raise KeyError(\"'paviaU' not found in the .mat file.\")\n",
    "\n",
    "# Check the shape of the hyperspectral image\n",
    "print(\"Hyperspectral image shape:\", hyperspectral_image.shape)\n",
    "\n",
    "# Convert to float32 for TensorFlow operations\n",
    "hyperspectral_image = hyperspectral_image.astype(np.float32)\n",
    "\n",
    "# Load the hyperspectral data using the spectral library\n",
    "data = hyperspectral_image  # Use the loaded hyperspectral image directly\n",
    "\n",
    "# Parameters\n",
    "patch_size = (144, 144)  # Size of patches to extract\n",
    "test_size = 0.2  # Proportion of data for testing\n",
    "validation_size = 0.1  # Proportion of data for validation\n",
    "downscale_factor = 4  # Factor to downscale patches\n",
    "nodata_value = -1  # Value that indicates \"no data\"\n",
    "group_size = 8 # Group size for spectral bands\n",
    "overlap_size = 2  # Overlap size for grouped bands\n",
    "\n",
    "# Function to group bands into overlapping subgroups\n",
    "def group_bands_with_overlap(data, group_size=6, overlap_size=2):\n",
    "    height, width, bands = data.shape\n",
    "    step_size = group_size - overlap_size  # Calculate step size based on overlap\n",
    "    grouped_data = []\n",
    "\n",
    "    # Create overlapping groups of bands\n",
    "    for g in range(0, bands - group_size + 1, step_size):\n",
    "        group = data[:, :, g:g + group_size]\n",
    "        grouped_data.append(group)\n",
    "    \n",
    "    return np.array(grouped_data)\n",
    "\n",
    "# Extract and downscale patches from hyperspectral data\n",
    "def extract_and_downscale_patches(data, patch_size, downscale_factor, nodata_value=0):\n",
    "    patches_hr = []\n",
    "    patches_lr = []\n",
    "    height, width, bands = data.shape\n",
    "\n",
    "    for i in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "        for j in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "            patch_hr = data[i:i + patch_size[0], j:j + patch_size[1], :]\n",
    "\n",
    "            # Check for nodata_value and skip patch extraction if present\n",
    "            if np.any(patch_hr == nodata_value):\n",
    "                continue\n",
    "            \n",
    "            patch_lr = tf.image.resize(patch_hr, \n",
    "                                        [patch_size[0] // downscale_factor, patch_size[1] // downscale_factor], \n",
    "                                        method='bilinear')\n",
    "            patches_hr.append(patch_hr)\n",
    "            patches_lr.append(patch_lr.numpy())  # Convert tensor to numpy\n",
    "\n",
    "    return np.array(patches_hr), np.array(patches_lr)\n",
    "\n",
    "# Group bands into overlapping subgroups\n",
    "grouped_data = group_bands_with_overlap(hyperspectral_image, group_size=group_size, overlap_size=overlap_size)\n",
    "\n",
    "# Extract and downscale patches for all groups\n",
    "all_patches_hr = []\n",
    "all_patches_lr = []\n",
    "\n",
    "for group in grouped_data:\n",
    "    patches_hr, patches_lr = extract_and_downscale_patches(group, patch_size, downscale_factor, nodata_value=nodata_value)\n",
    "    all_patches_hr.append(patches_hr)\n",
    "    all_patches_lr.append(patches_lr)\n",
    "\n",
    "# Concatenate patches from all groups\n",
    "all_patches_hr = np.concatenate(all_patches_hr, axis=0)\n",
    "all_patches_lr = np.concatenate(all_patches_lr, axis=0)\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches = len(all_patches_hr)\n",
    "\n",
    "# Calculate sizes for training, validation, and testing sets\n",
    "train_size = int((1 - test_size - validation_size) * num_patches)\n",
    "validation_size = int(validation_size * num_patches)\n",
    "test_size = num_patches - (train_size + validation_size)  # Explicit calculation of test size\n",
    "\n",
    "# Shuffle indices for splitting the data\n",
    "indices = np.arange(num_patches)\n",
    "np.random.shuffle(indices)\n",
    "all_patches_hr = all_patches_hr[indices]\n",
    "all_patches_lr = all_patches_lr[indices]\n",
    "\n",
    "# Split into training, validation, and testing sets\n",
    "X_train_hr, X_validation_hr, X_test_hr = np.split(all_patches_hr, [train_size, train_size + validation_size])\n",
    "X_train_lr, X_validation_lr, X_test_lr = np.split(all_patches_lr, [train_size, train_size + validation_size])\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train_hr shape:\", X_train_hr.shape)\n",
    "print(\"X_validation_hr shape:\", X_validation_hr.shape)\n",
    "print(\"X_test_hr shape:\", X_test_hr.shape)\n",
    "\n",
    "print(\"X_train_lr shape:\", X_train_lr.shape)\n",
    "print(\"X_validation_lr shape:\", X_validation_lr.shape)\n",
    "print(\"X_test_lr shape:\", X_test_lr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a033f-cd6b-49cf-8758-e8031d2a8835",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79df6a-3667-460f-8e01-042c3069d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **Channel Attention Block**\n",
    "def channel_attention_block(x, ratio=2):\n",
    "    channels = x.shape[-1]\n",
    "    shared_layer_one = Dense(channels // ratio, activation='relu', kernel_initializer='he_normal', use_bias=True)\n",
    "    shared_layer_two = Dense(channels, kernel_initializer='he_normal', use_bias=True)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling2D()(x)\n",
    "    avg_pool = Reshape((1, 1, channels))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "    \n",
    "    max_pool = GlobalAveragePooling2D()(x)\n",
    "    max_pool = Reshape((1, 1, channels))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "    \n",
    "    cbam_feature = Add()([avg_pool, max_pool])\n",
    "    cbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "    \n",
    "    return Multiply()([x, cbam_feature])\n",
    "\n",
    "# **Attention Augmented Convolution Block**\n",
    "def attention_augmented_conv(x, filters, kernel_size=(3, 3), num_heads=4):\n",
    "    conv_out = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    conv_out = BatchNormalization()(conv_out)\n",
    "    conv_out = LeakyReLU(alpha=0.1)(conv_out)\n",
    "\n",
    "    # **Spatial Attention using Multi-Head Self-Attention**\n",
    "    attn_out = MultiHeadAttention(num_heads=num_heads, key_dim=filters // num_heads)(conv_out, conv_out)\n",
    "    attn_out = Add()([conv_out, attn_out])  # Residual connection\n",
    "    attn_out = LayerNormalization()(attn_out)\n",
    "\n",
    "    return attn_out\n",
    "\n",
    "# **Enhanced Convolutional Block with Skip (Dense) Connection & Attention**\n",
    "def enhanced_conv_block(x, filters, kernel_size=(3, 3), use_skip_connection=True):\n",
    "    shortcut = x  # Save input as shortcut\n",
    "    x = attention_augmented_conv(x, filters, kernel_size)\n",
    "\n",
    "    # **Channel Attention**\n",
    "    x = channel_attention_block(x)\n",
    "\n",
    "    if use_skip_connection:\n",
    "        shortcut = Conv2D(filters, kernel_size=(1, 1), padding='same')(shortcut)\n",
    "        x = Concatenate()([x, shortcut])  # Dense (Skip) Connection\n",
    "    return x\n",
    "\n",
    "# **Enhanced Upsampling Block with Skip (Dense) Connection & Attention**\n",
    "def upsample_block(x, filters, scale=2, use_skip_connection=True):\n",
    "    shortcut = Conv2DTranspose(filters, (3, 3), strides=(scale, scale), padding='same')(x)  # Shortcut upsampling\n",
    "\n",
    "    x = Conv2DTranspose(filters, (3, 3), strides=(scale, scale), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # **Channel Attention**\n",
    "    x = channel_attention_block(x)\n",
    "\n",
    "    if use_skip_connection:\n",
    "        x = Concatenate()([x, shortcut])  # Dense (Skip) Connection\n",
    "    return x\n",
    "\n",
    "# **L2 Regularization Loss**\n",
    "def l2_loss(y_true, y_pred):\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred))  # Standard MSE loss\n",
    "    l2_loss_val = sum(K.sum(K.square(w)) for w in enhanced_cnn_sr_model.trainable_weights)  # L2 regularization\n",
    "    l2_penalty = 1e-4 * l2_loss_val  # Scale L2 penalty\n",
    "    return mse_loss + l2_penalty\n",
    "\n",
    "# **Spatial-Spectral Gradient Loss**\n",
    "def spatial_spectral_gradient_loss(y_true, y_pred):\n",
    "    grad_true_x, grad_true_y = tf.image.image_gradients(y_true)\n",
    "    grad_pred_x, grad_pred_y = tf.image.image_gradients(y_pred)\n",
    "\n",
    "    spatial_loss = K.mean(K.square(grad_true_x - grad_pred_x) + K.square(grad_true_y - grad_pred_y))\n",
    "\n",
    "    grad_true_spectral = tf.gradients(tf.reduce_mean(y_true, axis=[1, 2]), y_true)[0]\n",
    "    grad_pred_spectral = tf.gradients(tf.reduce_mean(y_pred, axis=[1, 2]), y_pred)[0]\n",
    "\n",
    "    spectral_loss = K.mean(K.square(grad_true_spectral - grad_pred_spectral))\n",
    "\n",
    "    return spatial_loss + spectral_loss\n",
    "\n",
    "# **Build Enhanced CNN Model with Attention Augmented Convolutions**\n",
    "def build_enhanced_cnn_sr_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # **Feature Extraction Layers with Skip (Dense) Connections & Attention**\n",
    "    x = enhanced_conv_block(inputs, filters=32, use_skip_connection=True)\n",
    "    x = enhanced_conv_block(x, filters=64, use_skip_connection=True)\n",
    "    x = enhanced_conv_block(x, filters=128, use_skip_connection=True)\n",
    "    \n",
    "    # **Upsampling Layers with Skip (Dense) Connections & Attention**\n",
    "    x = upsample_block(x, filters=64, scale=2, use_skip_connection=True)   # 2x upscaling\n",
    "    x = upsample_block(x, filters=32, scale=2, use_skip_connection=True)   # 4x upscaling\n",
    " #   x = upsample_block(x, filters=16, scale=2, use_skip_connection=True)   # 8x upscaling\n",
    "\n",
    "    # **Output Layer**\n",
    "    x_out = Conv2D(input_shape[-1], (3, 3), padding='same')(x)\n",
    "    x_out = Activation('linear')(x_out)\n",
    "    \n",
    "    # **Define Model**\n",
    "    model = Model(inputs=inputs, outputs=x_out, name=\"AAConv_Enhanced_CNN_SR_Model\")\n",
    "    return model\n",
    "\n",
    "# **Define Input Shape for Hyperspectral Data**\n",
    "input_shape = (36, 36, 8)  # Example input shape\n",
    "\n",
    "# **Build Model**\n",
    "enhanced_cnn_sr_model = build_enhanced_cnn_sr_model(input_shape)\n",
    "\n",
    "# **Combined Loss (L2 Loss + Spatial-Spectral Gradient Loss)**\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return l2_loss(y_true, y_pred) + spatial_spectral_gradient_loss(y_true, y_pred)\n",
    "\n",
    "# **Optimizer & Learning Rate**\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# **Compile Model**\n",
    "enhanced_cnn_sr_model.compile(optimizer=optimizer, loss=combined_loss)\n",
    "\n",
    "# **Display Model Summary**\n",
    "enhanced_cnn_sr_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b2deb-b521-41c5-a784-cc485133b96d",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d427597-b66a-4ec9-aa0a-cdb12c3176e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### # Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model and get the training history with early stopping\n",
    "history = enhanced_cnn_sr_model.fit(\n",
    "    X_train_lr, \n",
    "    X_train_hr, \n",
    "    epochs=2000, \n",
    "    batch_size=4, \n",
    "    validation_data=(X_validation_lr, X_validation_hr),\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback here\n",
    ")\n",
    "2\n",
    "# Visualize training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19609185-bb06-4921-9be5-fd83e3ca43c6",
   "metadata": {},
   "source": [
    "## Compute the metrices such as MPSNR, MSSIM, SAM, RMSE,CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85faafae-6c5e-4a93-8f49-03d670e46de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def psnr(y_true, y_pred, max_pixel=None):\n",
    "    \"\"\"\n",
    "    Compute PSNR for each spectral band separately and return the average.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth image, shape (H, W, B)\n",
    "        y_pred: Super-resolved image, shape (H, W, B)\n",
    "        max_pixel: Maximum pixel value (None = use actual max from y_true)\n",
    "    \n",
    "    Returns:\n",
    "        Average PSNR across all bands\n",
    "    \"\"\"\n",
    "    if max_pixel is None:\n",
    "        max_pixel = np.max(y_true)  # Auto-detect max value if not provided\n",
    "\n",
    "    B = y_true.shape[-1]  # Number of spectral bands\n",
    "    psnr_values = []\n",
    "    \n",
    "    for i in range(B):  # Loop over bands\n",
    "        mse = np.mean((y_true[..., i] - y_pred[..., i]) ** 2)\n",
    "        if mse == 0:\n",
    "            psnr_values.append(float('inf'))  # Perfect reconstruction\n",
    "        else:\n",
    "            psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "            psnr_values.append(psnr)\n",
    "    \n",
    "    return np.mean(psnr_values)  # Average across bands\n",
    "\n",
    "# Function to calculate SSIM with channel_axis\n",
    "def ssim_value(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true shape {y_true.shape} vs y_pred shape {y_pred.shape}\")\n",
    "    \n",
    "    data_range = y_true.max() - y_true.min()  # Calculate data range from y_true\n",
    "    ssim_val = ssim(y_true, y_pred, data_range=data_range, channel_axis=-1)\n",
    "    return ssim_val\n",
    "\n",
    "# Function to calculate Correlation Coefficient\n",
    "def correlation_coefficient(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    corr_matrix = np.corrcoef(y_true_flat, y_pred_flat)\n",
    "    corr_value = corr_matrix[0, 1]\n",
    "    return corr_value\n",
    "\n",
    "# Function to calculate Spectral Angle Mapper (SAM) in degrees\n",
    "def sam(y_true, y_pred):\n",
    "    y_true_reshaped = y_true.reshape(-1, y_true.shape[-1])\n",
    "    y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "    \n",
    "    non_zero_mask = (np.linalg.norm(y_true_reshaped, axis=1) > 1e-10) & (np.linalg.norm(y_pred_reshaped, axis=1) > 1e-10)\n",
    "    dot_product = np.sum(y_true_reshaped[non_zero_mask] * y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    norm_true = np.linalg.norm(y_true_reshaped[non_zero_mask], axis=1)\n",
    "    norm_pred = np.linalg.norm(y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        angles = np.arccos(np.clip(dot_product / (norm_true * norm_pred), -1.0, 1.0))\n",
    "    \n",
    "    if angles.size > 0:\n",
    "        sam_value_degrees = np.mean(angles) * (180 / np.pi)\n",
    "    else:\n",
    "        sam_value_degrees = 0\n",
    "    \n",
    "    return sam_value_degrees\n",
    "\n",
    "# Function to normalize the images\n",
    "def normalize(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    return (image - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "\n",
    "# Function to calculate Root Mean Squared Error (RMSE) for hyperspectral images (normalized)\n",
    "def rmse_bandwise(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shape mismatch between true and predicted images.\")\n",
    "    \n",
    "    bands = y_true.shape[-1]\n",
    "    rmse_per_band = []\n",
    "\n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        \n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)\n",
    "        rmse_band_value = np.sqrt(mse_band)\n",
    "        rmse_per_band.append(rmse_band_value)\n",
    "\n",
    "    # Normalize RMSE by the maximum value in y_true across all bands\n",
    "    max_value = np.max(y_true)\n",
    "    normalized_rmse = np.mean(rmse_per_band) / max_value\n",
    "    return normalized_rmse\n",
    "\n",
    "# Function to calculate ERGAS\n",
    "def ergas(y_true, y_pred, scale):\n",
    "    bands = y_true.shape[-1]\n",
    "    ergas_value = 0\n",
    "    \n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        mean_band_true = np.mean(band_true)\n",
    "        \n",
    "        # Calculate RMSE for the band without using a separate function\n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)  # Mean Squared Error for the band\n",
    "        rmse_band = np.sqrt(mse_band)  # Root Mean Squared Error for the band\n",
    "        \n",
    "        ergas_value += (rmse_band / mean_band_true) ** 2\n",
    "    \n",
    "    ergas_value = 100 * (1 / scale) * np.sqrt(ergas_value / bands)\n",
    "    return ergas_value\n",
    "\n",
    "# Assuming hybrid_sr_model is trained, and X_test_lr, X_test_hr are defined\n",
    "predicted_hr_images =  enhanced_cnn_sr_model.predict(X_test_lr, batch_size=4)\n",
    "\n",
    "downscale_factor = 4 # ERGAS downscale factor\n",
    "\n",
    "# Validate shapes match for test and predictions\n",
    "if predicted_hr_images.shape != X_test_hr.shape:\n",
    "    raise ValueError(f\"Shape mismatch: predicted_hr_images shape {predicted_hr_images.shape} vs X_test_hr shape {X_test_hr.shape}\")\n",
    "\n",
    "# Calculate metrics per test sample\n",
    "psnr_values, ssim_values, cc_values, sam_values, ergas_values, rmse_values = [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(X_test_hr)):\n",
    "    psnr_values.append(psnr(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ssim_values.append(ssim_value(X_test_hr[i], predicted_hr_images[i]))\n",
    "    cc_values.append(correlation_coefficient(X_test_hr[i], predicted_hr_images[i]))\n",
    "    sam_values.append(sam(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ergas_values.append(ergas(X_test_hr[i], predicted_hr_images[i], downscale_factor))\n",
    "    rmse_values.append(rmse_bandwise(X_test_hr[i], predicted_hr_images[i]))\n",
    "\n",
    "# Average metrics\n",
    "average_psnr = np.mean(psnr_values)\n",
    "average_ssim = np.mean(ssim_values)\n",
    "average_cc = np.mean(cc_values)\n",
    "average_sam = np.mean(sam_values)\n",
    "average_ergas = np.mean(ergas_values)\n",
    "average_rmse = np.mean(rmse_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Average PSNR on the test set:\", average_psnr)\n",
    "print(\"Average SSIM on the test set:\", average_ssim)\n",
    "print(\"Average SAM on the test set (in degrees):\", average_sam)\n",
    "print(\"Average Correlation Coefficient on the test set:\", average_cc)\n",
    "print(\"Average ERGAS on the test set:\", average_ergas)\n",
    "print(\"Average RMSE:\", average_rmse)  # Indicate RMSE is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ed4d6-e54f-43df-ab2e-d2ed8a91c9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
